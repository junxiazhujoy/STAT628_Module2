{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import copy\n",
    "import nltk\n",
    "import stemming\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from nltk.stem import PorterStemmer\n",
    "from stemming.porter2 import stem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "cf = open('bars_rev_tr_df.csv','r')\n",
    "\n",
    "file = csv.DictReader(cf)\n",
    "#print(file.fieldnames)\n",
    "\n",
    "for x in file:\n",
    "    line = {'business_id':x['business_id'],'date':x['date'],'stars':x['stars'],'text':x['text']}\n",
    "    data.append(line)\n",
    "\n",
    "cf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[0:1000000] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_5star=[]\n",
    "data_4star=[]\n",
    "data_3star=[]\n",
    "data_2star=[]\n",
    "data_1star=[]\n",
    "for i in range(len(data)):\n",
    "    if data[i]['stars']=='5':\n",
    "        data_5star.append(data[i])\n",
    "    elif data[i]['stars']=='4':\n",
    "        data_4star.append(data[i])\n",
    "    elif data[i]['stars']=='3':\n",
    "        data_3star.append(data[i])\n",
    "    elif data[i]['stars']=='2':\n",
    "        data_2star.append(data[i])\n",
    "    else:\n",
    "        data_1star.append(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383602"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_5star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "260378"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_4star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133669"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_3star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92780"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_2star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111846"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_1star)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewslist = copy.deepcopy(data[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\$)|(\\*)|(\\%)|(\\_)|(\\=)|(\\#)|(\\&)|(\\~)|(\\@)\")#[^\\P{P}-]+\n",
    "REPLACE_WITH_SPACE = re.compile(\"(\\n)|(\\-)|(\\/)|(\\d)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = REPLACE_NO_SPACE.sub(\"\", reviews)\n",
    "    reviews = REPLACE_WITH_SPACE.sub(\" \", reviews)\n",
    "    return reviews\n",
    "\n",
    "reviewsTEXT_clean = copy.deepcopy(reviewslist)\n",
    "\n",
    "for ind in range(len(reviewslist)):\n",
    "    texts = ''\n",
    "    texts = reviewslist[ind]['text']\n",
    "    texts = texts.lower()\n",
    "    texts = re.sub('n\\'t',' not', texts)\n",
    "    texts = re.sub('isnt','isn\\'t', texts)\n",
    "    texts = re.sub('wasnt','wasn\\'t', texts)\n",
    "    texts = re.sub('werent','weren\\'t', texts)\n",
    "    texts = re.sub('dont','don\\'t', texts)\n",
    "    texts = re.sub('doesnt','doesn\\'t', texts)\n",
    "    texts = re.sub('didnt','didn\\'t', texts)\n",
    "    texts = re.sub('hasnt','hasn\\'t', texts)\n",
    "    texts = re.sub('havent','haven\\'t', texts)\n",
    "    texts = re.sub('hadnt','hadn\\'t', texts)\n",
    "    texts = re.sub('mightnt','mightn\\'t', texts)\n",
    "    texts = re.sub('shouldnt','shouldn\\'t', texts)\n",
    "    texts = re.sub('isn','isn\\'t', texts)\n",
    "    texts = re.sub('wasn','wasn\\'t', texts)\n",
    "    texts = re.sub('weren','weren\\'t', texts)\n",
    "    texts = re.sub('don','don\\'t', texts)\n",
    "    texts = re.sub('doesn','doesn\\'t', texts)\n",
    "    texts = re.sub('didn','didn\\'t', texts)\n",
    "    texts = re.sub('hasn','hasn\\'t', texts)\n",
    "    texts = re.sub('haven','haven\\'t', texts)\n",
    "    texts = re.sub('hadn','hadn\\'t', texts)\n",
    "    texts = re.sub('mightn','mightn\\'t', texts)\n",
    "    texts = re.sub('shouldn','shouldn\\'t', texts)\n",
    "    \n",
    "    texts = re.sub('n\\'t',' not', texts)\n",
    "    \n",
    "    #add NOT_\n",
    "    pattern = r'\\.|\\;|\\!|\\?|\\,|\\)|\\(|\\:|\\'|\\\"|\\%'\n",
    "    list_text=re.split(pattern,texts)\n",
    "    \n",
    "    sent=''\n",
    "    for i in range(len(list_text)):\n",
    "        list_text[i] = re.sub('\\+','', list_text[i])\n",
    "        list_text[i] = re.sub('\\*','', list_text[i])\n",
    "        list_text[i] = re.sub('\\$','', list_text[i])\n",
    "        list_text[i] = re.sub('\\[','', list_text[i])\n",
    "        list_text[i] = re.sub('\\]','', list_text[i])\n",
    "        list_text[i] = re.sub('\\%','', list_text[i])\n",
    "        list_text[i] = re.sub('\\\\\\\\',' ', list_text[i])\n",
    "        matchObj1 = re.search(r'(.*)not (.*)',list_text[i])\n",
    "        matchObj2 = re.search(r'(.*) never (.*)',list_text[i])\n",
    "        \n",
    "        if matchObj1 != None :\n",
    "            sub=re.sub(r' ', \" notadd\", ' '+matchObj1.group(2))\n",
    "            list_text[i] = re.sub(matchObj1.group(2) ,sub, list_text[i])\n",
    "            list_text[i] = re.sub(r'not ','', list_text[i],1)\n",
    "            #list_text[i] = re.sub(',',' ', matchObj1.group(3))\n",
    "            sent = sent + list_text[i] + ' '\n",
    "        \n",
    "        elif matchObj2 != None :\n",
    "            sub=re.sub(r' ', \" notadd\", ' '+matchObj2.group(2))\n",
    "            list_text[i] = re.sub(matchObj2.group(2) ,sub, list_text[i])\n",
    "            list_text[i] = re.sub(r'never ','', list_text[i],1)\n",
    "            #list_text[i] = re.sub(',',' ', matchObj1.group(3))\n",
    "            sent = sent + list_text[i] + ' '\n",
    "        \n",
    "        else:\n",
    "            sent = sent + list_text[i] + ' '\n",
    "   \n",
    "    #print(sent)\n",
    "    #print(texts)\n",
    "    #print(texts)\n",
    "    text_clean=preprocess_reviews(sent)\n",
    "    #print(text_clean)\n",
    "    st = text_clean\n",
    "    st2 = \" \".join([stem(word) for word in st.split(\" \")])\n",
    "    text_clean = st2\n",
    "    \n",
    "    reviewsTEXT_clean[ind]['text']=text_clean\n",
    "    reviewsTEXT_clean[ind]['text_split']=text_clean.split()\n",
    "    reviewsTEXT_clean[ind]['freq']=nltk.FreqDist(reviewsTEXT_clean[ind]['text_split'])   \n",
    "    reviewsTEXT_clean[ind]['bigrams']=generate_ngrams(text_clean, 2)\n",
    "    reviewsTEXT_clean[ind]['bigrams_freq']=nltk.FreqDist(reviewsTEXT_clean[ind]['bigrams'])\n",
    "    \n",
    "#reviewsTEXT_clean[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select words due to frequency order\n",
    "AllFreq = reviewsTEXT_clean[0]['freq']\n",
    "for ind in range(len(reviewsTEXT_clean)-1):\n",
    "    freqs = reviewsTEXT_clean[ind+1]['freq']\n",
    "    AllFreq.update(freqs)\n",
    "    \n",
    "wordList = sorted(AllFreq.items(),key=lambda item:item[1],reverse=True)\n",
    "\n",
    "#choose the important ones--No.1-100\n",
    "WORDS=[x[0] for x in wordList]\n",
    "WORDS=WORDS[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "high-frequency words:\n",
      "['this', 'food', 'place', 'good', 'great', 'order', 'servic', 'notaddth', 'time', 'notadda', 'like', 'friend', 'go', 'get', 'notaddto', 'one', 'would', 'back', 'drink', 'notadd', 'us', 'restaur', 'love', 'realli', 'bar', 'tri', 'tabl', 'also', 'nice', 'came', 'best', 'menu', 'come', 'well', 'wait', 'no', 'even', 'got', 'notaddi', 'burger', 'price', 'beer', 'chees', 'night', 'staff', 'could', 'delici', 'look', 'fri', 'server', 'definit', 'littl', 'want', 'notaddit', 'ask', 'first', 'amaz', 'went', 'make', 'sauc', 'meal', 'flavor', 'pretti', 'chicken', 'dinner', 'side', 'experi', 'enjoy', 'tast', 'thing', 'has', 'notaddand', 'recommend', 'salad', 'star', 'peopl', 'notaddof', 'hour', 'notaddfor', 'alway', 'better', 'eat', 'notaddin', 'notaddb', 'atmospher', 'much', 'everyth', 'perfect', 'wine', 'minut', 'took', 'made', 'way', 'top', 'right', 'steak', 'notaddw', 'notaddthat', 'still', 'take']\n"
     ]
    }
   ],
   "source": [
    "#stop_words = set(stopwords.words('english')) \n",
    "stop_words = {'who', 'how', 'him', 'can', 'than', 'these', 'your', 'the', 'while', 'don', 'of', 'on', 'had', 'there', \"you've\", 'that', 'having', 'himself', \"mustn't\", 'same', 'are', \"won't\", 'then', 'itself', 'doing', 'from', 'both', 'where', 'wouldn', 'me', 'off', 'because', 'isn', \"you'd\", 'whom', 'mustn', 'is', 'themselves', 'no', 'very', 'up', 'd', 'ma', 'yours', 'been', 'ain', 'will', 'a', 'most', 'did', 'with', 'o', 'this', 'during', 'i', \"mightn't\", \"isn't\", 'being', 'couldn', 'them', 'not', 'such', 'her', 'some', 'only', \"didn't\", 'should', 'after', 'our', 'down', 'here', 'about', 'herself', \"hadn't\", 'but', 'he', 'an', 'am', 't', 'they', 'again', 'll', 've', 'didn', 'into', 'needn', 're', 'nor', \"couldn't\", 'above', 'all', \"should've\", 'm', 'other', 'below', \"she's\", 'just', 'between', 'hasn', 'own', 'yourselves', 'until', 'too', 'which', \"shouldn't\", 's', \"it's\", 'his', 'y', 'to', 'over', 'hadn', \"shan't\", 'does', 'weren', 'shouldn', 'under', \"aren't\", 'be', \"don't\", 'any', 'or', \"haven't\", 'she', 'aren', 'against', 'we', 'in', 'ourselves', 'have', 'won', \"wasn't\", 'wasn', 'you', 'what', 'mightn', \"weren't\", 'doesn', 'hers', 'myself', 'shan', 'before', 'more', \"wouldn't\", 'were', 'each', \"doesn't\", 'through', 'for', \"hasn't\", 'by', 'now', 'do', 'has', 'those', 'few', \"you'll\", 'once', 'it', 'their', 'further', \"you're\", 'my', 'at', 'when', 'yourself', 'why', 'as', 'was', 'and', 'out', \"needn't\", 'if', 'haven', 'its', 'theirs', \"that'll\", 'so', 'ours'}\n",
    "ps = PorterStemmer()\n",
    "stop_words_stem=[]\n",
    "for w in stop_words:\n",
    "    stop_words_stem.append(ps.stem(w))\n",
    "negWords=set([\"wouldn't\",'isn','wasn',\"weren't\", \"haven't\", \"hasn't\", \"couldn't\", \"isn't\", 'doesn','hasn',\"mustn't\", 'mightn', 'shan', 'no', \"wasn't\",'aren', \"didn't\", \"hadn't\",\"don't\",'nor',\"won't\",'weren',\"doesn't\",\"needn't\", 'shouldn',\"mightn't\",\"shan't\", 'wouldn',\"shouldn't\",'hadn'])\n",
    "negWords_stem=[]\n",
    "for w in negWords:\n",
    "    negWords_stem.append(ps.stem(w))\n",
    "d=set(['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z','Ã ','{sigh}'])\n",
    "stopWords_stem=set(stop_words_stem)-set(negWords_stem)\n",
    "stopWords_stem.update(d)\n",
    "stopWords_stem.add('was')\n",
    "\n",
    "WORDS=[x for x in WORDS if x not in stopWords_stem]\n",
    "\n",
    "\n",
    "print('high-frequency words:')\n",
    "print(WORDS[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep those high-frequency words in text, so that when doing Vectorizer it will not 'out of memory'.\n",
    "for i in range(len(reviewsTEXT_clean)):\n",
    "    reviewsTEXT_clean[i]['text'] = ''\n",
    "    for ind in reviewsTEXT_clean[i]['text_split']:\n",
    "        if ind in WORDS:\n",
    "            reviewsTEXT_clean[i]['text'] = reviewsTEXT_clean[i]['text'] + ind +' '\n",
    "        else:\n",
    "            reviewsTEXT_clean[i]['text'] = reviewsTEXT_clean[i]['text']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create list of texts\n",
    "texts= [x['text'] for x in reviewsTEXT_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorizer = CountVectorizer(token_pattern=r'\\b[^\\d\\W]+\\b')\n",
    "vectorizer = CountVectorizer()\n",
    "#X = vectorizer.fit_transform(texts)\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(texts))\n",
    "\n",
    "X=tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       this      food     place      good     great     order    servic  \\\n",
      "0  0.000000  0.000000  0.000000  0.080864  0.080006  0.000000  0.000000   \n",
      "1  0.070023  0.141921  0.076696  0.000000  0.000000  0.000000  0.084456   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.078301   \n",
      "3  0.128387  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.141987  0.000000  0.076253   \n",
      "5  0.049764  0.000000  0.000000  0.000000  0.055881  0.000000  0.060022   \n",
      "6  0.099742  0.101078  0.218494  0.000000  0.112003  0.000000  0.120301   \n",
      "7  0.057703  0.058476  0.000000  0.000000  0.000000  0.077526  0.069597   \n",
      "8  0.189375  0.054831  0.237052  0.092114  0.091137  0.036347  0.032630   \n",
      "9  0.026332  0.000000  0.028841  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "   notaddth      time   notadda   ...    notaddpay  combo  brown  ambienc  \\\n",
      "0  0.000000  0.000000  0.000000   ...          0.0    0.0    0.0      0.0   \n",
      "1  0.096443  0.000000  0.000000   ...          0.0    0.0    0.0      0.0   \n",
      "2  0.000000  0.000000  0.192682   ...          0.0    0.0    0.0      0.0   \n",
      "3  0.000000  0.000000  0.000000   ...          0.0    0.0    0.0      0.0   \n",
      "4  0.087076  0.000000  0.000000   ...          0.0    0.0    0.0      0.0   \n",
      "5  0.068541  0.000000  0.073850   ...          0.0    0.0    0.0      0.0   \n",
      "6  0.000000  0.000000  0.000000   ...          0.0    0.0    0.0      0.0   \n",
      "7  0.158950  0.153310  0.000000   ...          0.0    0.0    0.0      0.0   \n",
      "8  0.000000  0.143755  0.080295   ...          0.0    0.0    0.0      0.0   \n",
      "9  0.000000  0.104940  0.117229   ...          0.0    0.0    0.0      0.0   \n",
      "\n",
      "   prompt  upstair  notaddonc  notaddsweet  sorri  valley  \n",
      "0     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "1     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "2     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "3     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "4     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "5     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "6     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "7     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "8     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "9     0.0      0.0        0.0          0.0    0.0     0.0  \n",
      "\n",
      "[10 rows x 891 columns]\n"
     ]
    }
   ],
   "source": [
    "#vectorizer.get_feature_names()\n",
    "X_df=pd.DataFrame(X.A,columns=vectorizer.get_feature_names())\n",
    "\n",
    "Reviews_df=X_df[WORDS]\n",
    "print(Reviews_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "####add ngrams\n",
    "#select bigrams due to frequency order\n",
    "AllBiFreq = reviewsTEXT_clean[0]['bigrams_freq']\n",
    "for ind in range(len(reviewsTEXT_clean)-1):\n",
    "    Bifreqs = reviewsTEXT_clean[ind+1]['bigrams_freq']\n",
    "    AllBiFreq.update(Bifreqs)\n",
    "    \n",
    "BiwordList = sorted(AllBiFreq.items(),key=lambda item:item[1],reverse=True)\n",
    "BiwordList=BiwordList[0:500]\n",
    "\n",
    "#choose the important ones--No.1-100\n",
    "BiWORDS=[x[0] for x in BiwordList]\n",
    "Biwordfreq = {}\n",
    "for i in range(len(BiwordList)):\n",
    "    if len(list(set(BiwordList[i][0].split()).difference(stopWords_stem))) == 2:\n",
    "        Biwordfreq[BiwordList[i][0]]=BiwordList[i][1]\n",
    "\n",
    "BiWORDS=list(Biwordfreq.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviewsTEXT_clean)):\n",
    "    reviewsTEXT_clean[i]['text'] = ' '\n",
    "    for ind in reviewsTEXT_clean[i]['bigrams']:\n",
    "        if ind in BiWORDS:\n",
    "            reviewsTEXT_clean[i]['text'] = reviewsTEXT_clean[i]['text'] + ind +' '\n",
    "        else:\n",
    "            reviewsTEXT_clean[i]['text'] = reviewsTEXT_clean[i]['text']\n",
    "\n",
    "\n",
    "\n",
    "#create list of texts\n",
    "texts= [x['text'] for x in reviewsTEXT_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   back ca  back custom  back even  back first  back go  back great  \\\n",
      "0      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "1      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "2      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "3      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "4      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "5      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "6      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "7      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "8      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "9      0.0          0.0        0.0         0.0      0.0         0.0   \n",
      "\n",
      "   back happi  back high  back next  back notaddat     ...      time wo  \\\n",
      "0         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "1         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "2         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "3         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "4         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "5         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "6         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "7         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "8         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "9         0.0        0.0        0.0            0.0     ...          0.0   \n",
      "\n",
      "   vega custom  vega even  vega first  vega great  vega las  vega love  \\\n",
      "0          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "1          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "2          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "3          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "4          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "5          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "6          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "7          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "8          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "9          0.0        0.0         0.0         0.0       0.0        0.0   \n",
      "\n",
      "   vega recommend  vega this  wo notaddb  \n",
      "0             0.0        0.0         0.0  \n",
      "1             0.0        0.0         0.0  \n",
      "2             0.0        0.0         0.0  \n",
      "3             0.0        0.0         0.0  \n",
      "4             0.0        0.0         0.0  \n",
      "5             0.0        0.0         0.0  \n",
      "6             0.0        0.0         0.0  \n",
      "7             0.0        0.0         0.0  \n",
      "8             0.0        0.0         0.0  \n",
      "9             0.0        0.0         0.0  \n",
      "\n",
      "[10 rows x 371 columns]\n",
      "   notaddfor notadda  great servic  notaddgo notaddback  high recommend  \\\n",
      "0                0.0      0.000000                  0.0        0.000000   \n",
      "1                0.0      0.000000                  0.0        0.000000   \n",
      "2                1.0      0.000000                  0.0        0.000000   \n",
      "3                0.0      0.000000                  0.0        0.000000   \n",
      "4                0.0      0.480236                  0.0        0.442808   \n",
      "5                0.0      0.000000                  0.0        0.000000   \n",
      "6                0.0      0.000000                  0.0        0.000000   \n",
      "7                0.0      0.000000                  0.0        0.000000   \n",
      "8                0.0      0.000000                  0.0        0.000000   \n",
      "9                0.0      0.000000                  0.0        0.000000   \n",
      "\n",
      "   come back  much better  las vega  beer select  even though  \\\n",
      "0        0.0          0.0       0.0          0.0          0.0   \n",
      "1        0.0          0.0       0.0          0.0          0.0   \n",
      "2        0.0          0.0       0.0          0.0          0.0   \n",
      "3        0.0          0.0       0.0          0.0          0.0   \n",
      "4        0.0          0.0       0.0          0.0          0.0   \n",
      "5        0.0          0.0       0.0          0.0          0.0   \n",
      "6        0.0          0.0       0.0          0.0          0.0   \n",
      "7        0.0          0.0       0.0          0.0          0.0   \n",
      "8        0.0          0.0       0.0          0.0          0.0   \n",
      "9        0.0          0.0       0.0          0.0          0.0   \n",
      "\n",
      "   notaddthi notaddplac    ...      ca notaddwait  this place  first time  \\\n",
      "0              0.000000    ...                0.0    0.000000         0.0   \n",
      "1              0.572528    ...                0.0    0.301671         0.0   \n",
      "2              0.000000    ...                0.0    0.000000         0.0   \n",
      "3              0.000000    ...                0.0    0.000000         0.0   \n",
      "4              0.000000    ...                0.0    0.000000         0.0   \n",
      "5              0.000000    ...                0.0    0.000000         0.0   \n",
      "6              0.000000    ...                0.0    0.326706         0.0   \n",
      "7              0.000000    ...                0.0    0.000000         0.0   \n",
      "8              0.000000    ...                0.0    0.293684         0.0   \n",
      "9              0.795151    ...                0.0    0.000000         0.0   \n",
      "\n",
      "   go back  custom servic  pretti good  great food  great place  \\\n",
      "0      0.0            0.0     1.000000    0.000000      0.00000   \n",
      "1      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "2      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "3      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "4      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "5      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "6      0.0            0.0     0.000000    0.609551      0.00000   \n",
      "7      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "8      0.0            0.0     0.172111    0.000000      0.53108   \n",
      "9      0.0            0.0     0.000000    0.000000      0.00000   \n",
      "\n",
      "   notaddt notadd  good food  \n",
      "0             0.0        0.0  \n",
      "1             0.0        0.0  \n",
      "2             0.0        0.0  \n",
      "3             0.0        0.0  \n",
      "4             0.0        0.0  \n",
      "5             0.0        0.0  \n",
      "6             0.0        0.0  \n",
      "7             0.0        0.0  \n",
      "8             0.0        0.0  \n",
      "9             0.0        0.0  \n",
      "\n",
      "[10 rows x 40 columns]\n",
      "       this      food     place      good     great     order    servic  \\\n",
      "0  0.000000  0.000000  0.000000  0.080864  0.080006  0.000000  0.000000   \n",
      "1  0.070023  0.141921  0.076696  0.000000  0.000000  0.000000  0.084456   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.078301   \n",
      "3  0.128387  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "4  0.000000  0.000000  0.000000  0.000000  0.141987  0.000000  0.076253   \n",
      "5  0.049764  0.000000  0.000000  0.000000  0.055881  0.000000  0.060022   \n",
      "6  0.099742  0.101078  0.218494  0.000000  0.112003  0.000000  0.120301   \n",
      "7  0.057703  0.058476  0.000000  0.000000  0.000000  0.077526  0.069597   \n",
      "8  0.189375  0.054831  0.237052  0.092114  0.091137  0.036347  0.032630   \n",
      "9  0.026332  0.000000  0.028841  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "   notaddth      time   notadda     ...       this place  first time  go back  \\\n",
      "0  0.000000  0.000000  0.000000     ...         0.000000         0.0      0.0   \n",
      "1  0.096443  0.000000  0.000000     ...         0.301671         0.0      0.0   \n",
      "2  0.000000  0.000000  0.192682     ...         0.000000         0.0      0.0   \n",
      "3  0.000000  0.000000  0.000000     ...         0.000000         0.0      0.0   \n",
      "4  0.087076  0.000000  0.000000     ...         0.000000         0.0      0.0   \n",
      "5  0.068541  0.000000  0.073850     ...         0.000000         0.0      0.0   \n",
      "6  0.000000  0.000000  0.000000     ...         0.326706         0.0      0.0   \n",
      "7  0.158950  0.153310  0.000000     ...         0.000000         0.0      0.0   \n",
      "8  0.000000  0.143755  0.080295     ...         0.293684         0.0      0.0   \n",
      "9  0.000000  0.104940  0.117229     ...         0.000000         0.0      0.0   \n",
      "\n",
      "   custom servic  pretti good  great food  great place  notaddt notadd  \\\n",
      "0            0.0     1.000000    0.000000      0.00000             0.0   \n",
      "1            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "2            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "3            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "4            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "5            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "6            0.0     0.000000    0.609551      0.00000             0.0   \n",
      "7            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "8            0.0     0.172111    0.000000      0.53108             0.0   \n",
      "9            0.0     0.000000    0.000000      0.00000             0.0   \n",
      "\n",
      "   good food  business_id  \n",
      "0        0.0        71871  \n",
      "1        0.0       139555  \n",
      "2        0.0        40775  \n",
      "3        0.0        18125  \n",
      "4        0.0       125478  \n",
      "5        0.0         9439  \n",
      "6        0.0       161100  \n",
      "7        0.0        88584  \n",
      "8        0.0        88584  \n",
      "9        0.0       154175  \n",
      "\n",
      "[10 rows x 932 columns]\n"
     ]
    }
   ],
   "source": [
    "#vectorizer = CountVectorizer(token_pattern=r'\\b[^\\d\\W]+\\b')\n",
    "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
    "#X = vectorizer.fit_transform(texts)\n",
    "transformer = TfidfTransformer()\n",
    "\n",
    "tfidf = transformer.fit_transform(vectorizer.fit_transform(texts))\n",
    "\n",
    "X_ngrams=tfidf\n",
    "X_ngrams_df=pd.DataFrame(X_ngrams.A,columns = vectorizer.get_feature_names())\n",
    "print(X_ngrams_df.head(10))\n",
    "Reviews_ngrams_df=X_ngrams_df[list(set(Biwordfreq.keys()).intersection(set(vectorizer.get_feature_names())))]\n",
    "Reviews_ngrams_df\n",
    "print(Reviews_ngrams_df.head(10))\n",
    "\n",
    "Reviews_df=pd.concat([Reviews_df,Reviews_ngrams_df],axis=1)\n",
    "\n",
    "#Add Business ID in the data frame\n",
    "businessIDs=[x['business_id'] for x in reviewsTEXT_clean]\n",
    "Reviews_df['business_id']=businessIDs\n",
    "print(Reviews_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "DataFrame.to_csv(Reviews_df,\"clean.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
