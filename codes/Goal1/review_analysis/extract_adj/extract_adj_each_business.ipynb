{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json \n",
    "import copy\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import sklearn\n",
    "from nltk.stem import PorterStemmer\n",
    "from stemming.porter2 import stem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load our pos/neg corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos=list(set(open(\"positive.txt\", 'r').read().split('\\',\\'')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg=list(set(open(\"negative.txt\", 'r').read().split('\\',\\'')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.remove('poor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(pos)):\n",
    "    temp=str('NOT_'+str(pos[i]))\n",
    "    neg.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [] \n",
    "cf = open('bars_rev_tr_df.csv','r')\n",
    "\n",
    "file = csv.DictReader(cf)\n",
    "#print(file.fieldnames)\n",
    "\n",
    "for x in file:\n",
    "    line = {'business_id':x['business_id'],'date':x['date'],'stars':x['stars'],'text':x['text']}\n",
    "    data.append(line)\n",
    "\n",
    "cf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "id = open('uniq_id_lvbars.txt','r')\n",
    "id_str=id.read()\n",
    "id.close()\n",
    "id_list=id_str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_night=[]\n",
    "for i in range(len(data)):\n",
    "    if data[i]['business_id'] in id_list:\n",
    "        dat_night.append(data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dat_night=dat_night[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewslist = copy.deepcopy(dat_night)\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\()|(\\))|(\\[)|(\\])|(\\$)|(\\*)|(\\%)|(\\=)|(\\#)|(\\&)|(\\~)|(\\@)\")#[^\\P{P}-]+\n",
    "REPLACE_WITH_SPACE = re.compile(\"(\\n)|(\\-)|(\\/)|(\\d)\")\n",
    "\n",
    "def preprocess_reviews(reviews):\n",
    "    reviews = REPLACE_NO_SPACE.sub(\"\", reviews)\n",
    "    reviews = REPLACE_WITH_SPACE.sub(\" \", reviews)\n",
    "    return reviews\n",
    "\n",
    "reviewsTEXT_clean = copy.deepcopy(reviewslist)\n",
    "\n",
    "for ind in range(len(reviewslist)):\n",
    "    texts = ''\n",
    "    texts = reviewslist[ind]['text']\n",
    "    texts = texts.lower()\n",
    "    \n",
    "    texts = re.sub('n\\'t',' not', texts)\n",
    "    \n",
    "    texts = re.sub('isnt','isn\\'t', texts)\n",
    "    texts = re.sub('wasnt','wasn\\'t', texts)\n",
    "    texts = re.sub('werent','weren\\'t', texts)\n",
    "    texts = re.sub('dont','don\\'t', texts)\n",
    "    texts = re.sub('doesnt','doesn\\'t', texts)\n",
    "    texts = re.sub('didnt','didn\\'t', texts)\n",
    "    texts = re.sub('hasnt','hasn\\'t', texts)\n",
    "    texts = re.sub('havent','haven\\'t', texts)\n",
    "    texts = re.sub('hadnt','hadn\\'t', texts)\n",
    "    texts = re.sub('mightnt','mightn\\'t', texts)\n",
    "    texts = re.sub('shouldnt','shouldn\\'t', texts)\n",
    "    texts = re.sub('isn','isn\\'t', texts)\n",
    "    texts = re.sub('wasn','wasn\\'t', texts)\n",
    "    texts = re.sub('weren','weren\\'t', texts)\n",
    "    texts = re.sub('don','don\\'t', texts)\n",
    "    texts = re.sub('doesn','doesn\\'t', texts)\n",
    "    texts = re.sub('didn','didn\\'t', texts)\n",
    "    texts = re.sub('hasn','hasn\\'t', texts)\n",
    "    texts = re.sub('haven','haven\\'t', texts)\n",
    "    texts = re.sub('hadn','hadn\\'t', texts)\n",
    "    texts = re.sub('mightn','mightn\\'t', texts)\n",
    "    texts = re.sub('shouldn','shouldn\\'t', texts)\n",
    "    texts = re.sub('won\\'t','will not', texts)\n",
    "    \n",
    "    texts = re.sub('n\\'t',' not', texts)\n",
    "    \n",
    "    #add NOT_\n",
    "    pattern = r'\\.|\\;|\\!|\\?|\\,|\\)|\\(|\\:|\\'|\\\"|\\%'\n",
    "    list_text=re.split(pattern,texts)\n",
    "    \n",
    "    sent=''\n",
    "    for i in range(len(list_text)):\n",
    "        list_text[i] = re.sub('\\+','', list_text[i])\n",
    "        list_text[i] = re.sub('\\*','', list_text[i])\n",
    "        list_text[i] = re.sub('\\$','', list_text[i])\n",
    "        list_text[i] = re.sub('\\[','', list_text[i])\n",
    "        list_text[i] = re.sub('\\]','', list_text[i])\n",
    "        list_text[i] = re.sub('\\%','', list_text[i])\n",
    "        list_text[i] = re.sub('\\\\\\\\',' ', list_text[i])\n",
    "        matchObj1 = re.search(r'(.*)not (.*)',list_text[i])\n",
    "        matchObj2 = re.search(r'(.*) never (.*)',list_text[i])\n",
    "        \n",
    "        if matchObj1 != None :\n",
    "            sub=re.sub(r' ', \" NOT_\", ' '+matchObj1.group(2))\n",
    "            list_text[i] = re.sub(matchObj1.group(2) ,sub, list_text[i])\n",
    "            list_text[i] = re.sub(r'not ','', list_text[i],1)\n",
    "            #list_text[i] = re.sub(',',' ', matchObj1.group(3))\n",
    "            sent = sent + list_text[i] + ' '\n",
    "        \n",
    "        elif matchObj2 != None :\n",
    "            sub=re.sub(r' ', \" NOT_\", ' '+matchObj2.group(2))\n",
    "            list_text[i] = re.sub(matchObj2.group(2) ,sub, list_text[i])\n",
    "            list_text[i] = re.sub(r'never ','', list_text[i],1)\n",
    "            #list_text[i] = re.sub(',',' ', matchObj1.group(3))\n",
    "            sent = sent + list_text[i] + ' '\n",
    "        \n",
    "        else:\n",
    "            sent = sent + list_text[i] + ' '\n",
    "   \n",
    "    text_clean=preprocess_reviews(sent)\n",
    "    \n",
    "    rvs2 = \" \".join([stem(word) for word in text_clean.split(\" \")])\n",
    "    reviewsTEXT_clean[ind]['text']=rvs2\n",
    "    reviewsTEXT_clean[ind]['text_split']=rvs2.split()\n",
    "\n",
    "    \n",
    "#reviewsTEXT_clean[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cocktail adj for each business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(id_list)\n",
    "cock_adj_list=[]\n",
    "for i in range(len(id_list)):\n",
    "    temp=[]\n",
    "    count_pos=0\n",
    "    count_neg=0\n",
    "    list_pos=[]\n",
    "    list_neg=[]\n",
    "    dict={}\n",
    "    dict['business_id']=id_list[i]\n",
    "    for j in range(len(reviewsTEXT_clean)):\n",
    "        if reviewsTEXT_clean[j]['business_id'] == id_list[i]:\n",
    "            temp.append(reviewsTEXT_clean[j])\n",
    "    \n",
    "    word_count=0\n",
    "    for m in range(len(temp)):\n",
    "        word_count+=len(temp[m]['text_split'])\n",
    "        if 'cocktail' in temp[m]['text_split']:\n",
    "            index_list=[p for p,x in enumerate(temp[m]['text_split']) if x=='cocktail']\n",
    "            for index in index_list:\n",
    "                if (index-2 >= 0) and (temp[m]['text_split'][index-2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-2])\n",
    "                elif (index-2 >= 0) and (temp[m]['text_split'][index-2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-2])\n",
    "            \n",
    "                if (index-1 >= 0) and (temp[m]['text_split'][index-1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-1])\n",
    "                elif (index-1 >= 0) and (temp[m]['text_split'][index-1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-1])\n",
    "            \n",
    "                if (index+2 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+1])\n",
    "                elif (index+2 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+1])\n",
    "            \n",
    "                if (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+2])\n",
    "                elif (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+2])\n",
    "            \n",
    "    dict['pos_words']=list_pos\n",
    "    dict['neg_words']=list_neg\n",
    "    dict['pos_count']=count_pos\n",
    "    dict['neg_count']=count_neg\n",
    "    dict['all_mention']=count_pos+count_neg\n",
    "    dict['review_count']=len(temp)\n",
    "    dict['word_count']=word_count\n",
    "    cock_adj_list.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "cock_adj_df=pd.DataFrame.from_dict(cock_adj_list)\n",
    "cock_adj_df=cock_adj_df[['business_id','neg_words','neg_count','pos_words','pos_count','all_mention','review_count','word_count']]\n",
    "cock_adj_df=cock_adj_df.sort_values(by=\"all_mention\", ascending=False)\n",
    "cock_adj_df.to_csv('cocktail_adj.csv',index=False)\n",
    "stars = pd.read_csv('LVbars_Business_withStars.csv')\n",
    "adj = pd.read_csv('cocktail_adj.csv')\n",
    "df = pd.merge(adj, stars, how='left', on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_neg=nltk.FreqDist(df['neg_words'][i][2:(len(df['neg_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_neg.keys()))>=5:\n",
    "        neg_top5.append(list(dict_neg.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        neg_top5.append(list(dict_neg.keys()))\n",
    "    else:\n",
    "        neg_top5.append('NULL')\n",
    "df['neg_top5']=neg_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_pos=nltk.FreqDist(df['pos_words'][i][2:(len(df['pos_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_pos.keys()))>=5:\n",
    "        pos_top5.append(list(dict_pos.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        pos_top5.append(list(dict_pos.keys()))\n",
    "    else:\n",
    "        pos_top5.append('NULL')\n",
    "df['pos_top5']=pos_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['business_id','neg_words','neg_count','neg_top5','pos_words','pos_count','pos_top5','all_mention','review_count','word_count','stars']]\n",
    "df.to_csv('cocktail_adj.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beer adj for each business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_adj_list=[]\n",
    "for i in range(len(id_list)):\n",
    "    temp=[]\n",
    "    count_pos=0\n",
    "    count_neg=0\n",
    "    list_pos=[]\n",
    "    list_neg=[]\n",
    "    dict={}\n",
    "    dict['business_id']=id_list[i]\n",
    "    for j in range(len(reviewsTEXT_clean)):\n",
    "        if reviewsTEXT_clean[j]['business_id'] == id_list[i]:\n",
    "            temp.append(reviewsTEXT_clean[j])\n",
    "    \n",
    "    word_count=0\n",
    "    for m in range(len(temp)):\n",
    "        word_count+=len(temp[m]['text_split'])\n",
    "        if 'beer' in temp[m]['text_split']:\n",
    "            index_list=[p for p,x in enumerate(temp[m]['text_split']) if x=='beer']\n",
    "            for index in index_list:\n",
    "                if (index-2 >= 0) and (temp[m]['text_split'][index-2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-2])\n",
    "                elif (index-2 >= 0) and (temp[m]['text_split'][index-2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-2])\n",
    "            \n",
    "                if (index-1 >= 0) and (temp[m]['text_split'][index-1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-1])\n",
    "                elif (index-1 >= 0) and (temp[m]['text_split'][index-1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-1])\n",
    "            \n",
    "                if (index+2 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+1])\n",
    "                elif (index+2 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+1])\n",
    "            \n",
    "                if (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+2])\n",
    "                elif (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+2])\n",
    "            \n",
    "    dict['pos_words']=list_pos\n",
    "    dict['neg_words']=list_neg\n",
    "    dict['pos_count']=count_pos\n",
    "    dict['neg_count']=count_neg\n",
    "    dict['all_mention']=count_pos+count_neg\n",
    "    dict['review_count']=len(temp)\n",
    "    dict['word_count']=word_count\n",
    "    beer_adj_list.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_adj_df=pd.DataFrame.from_dict(beer_adj_list)\n",
    "beer_adj_df=beer_adj_df[['business_id','neg_words','neg_count','pos_words','pos_count','all_mention','review_count','word_count']]\n",
    "beer_adj_df=beer_adj_df.sort_values(by=\"all_mention\", ascending=False)\n",
    "beer_adj_df.to_csv('cocktail_adj.csv',index=False)\n",
    "stars = pd.read_csv('LVbars_Business_withStars.csv')\n",
    "adj = pd.read_csv('cocktail_adj.csv')\n",
    "df = pd.merge(adj, stars, how='left', on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_neg=nltk.FreqDist(df['neg_words'][i][2:(len(df['neg_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_neg.keys()))>=5:\n",
    "        neg_top5.append(list(dict_neg.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        neg_top5.append(list(dict_neg.keys()))\n",
    "    else:\n",
    "        neg_top5.append('NULL')\n",
    "df['neg_top5']=neg_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_pos=nltk.FreqDist(df['pos_words'][i][2:(len(df['pos_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_pos.keys()))>=5:\n",
    "        pos_top5.append(list(dict_pos.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        pos_top5.append(list(dict_pos.keys()))\n",
    "    else:\n",
    "        pos_top5.append('NULL')\n",
    "df['pos_top5']=pos_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['business_id','neg_words','neg_count','neg_top5','pos_words','pos_count','pos_top5','all_mention','review_count','word_count','stars']]\n",
    "df.to_csv('beer_adj.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# craft beer adj for each business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(id_list)\n",
    "craft_adj_list=[]\n",
    "for i in range(len(id_list)):\n",
    "    temp=[]\n",
    "    count_pos=0\n",
    "    count_neg=0\n",
    "    list_pos=[]\n",
    "    list_neg=[]\n",
    "    dict={}\n",
    "    dict['business_id']=id_list[i]\n",
    "    for j in range(len(reviewsTEXT_clean)):\n",
    "        if reviewsTEXT_clean[j]['business_id'] == id_list[i]:\n",
    "            temp.append(reviewsTEXT_clean[j])\n",
    "    \n",
    "    word_count=0\n",
    "    for m in range(len(temp)):\n",
    "        word_count+=len(temp[m]['text_split'])\n",
    "        if 'craft beer' in temp[m]['text']:\n",
    "            index_list=[p for p,x in enumerate(temp[m]['text_split']) if x=='craft']\n",
    "            for index in index_list:\n",
    "                if (index-2 >= 0) and (temp[m]['text_split'][index-2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-2])\n",
    "                elif (index-2 >= 0) and (temp[m]['text_split'][index-2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-2])\n",
    "            \n",
    "                if (index-1 >= 0) and (temp[m]['text_split'][index-1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-1])\n",
    "                elif (index-1 >= 0) and (temp[m]['text_split'][index-1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-1])\n",
    "            \n",
    "                if (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+2])\n",
    "                elif (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+2])\n",
    "            \n",
    "                if (index+4 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+3] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+3])\n",
    "                elif (index+4 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+3] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+3])\n",
    "            \n",
    "    dict['pos_words']=list_pos\n",
    "    dict['neg_words']=list_neg\n",
    "    dict['pos_count']=count_pos\n",
    "    dict['neg_count']=count_neg\n",
    "    dict['all_mention']=count_pos+count_neg\n",
    "    dict['review_count']=len(temp)\n",
    "    dict['word_count']=word_count\n",
    "    craft_adj_list.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "craft_adj_df=pd.DataFrame.from_dict(craft_adj_list)\n",
    "craft_adj_df=craft_adj_df[['business_id','neg_words','neg_count','pos_words','pos_count','all_mention','review_count','word_count']]\n",
    "craft_adj_df=craft_adj_df.sort_values(by=\"all_mention\", ascending=False)\n",
    "craft_adj_df.to_csv('craft_adj.csv',index=False)\n",
    "\n",
    "adj = pd.read_csv('craft_adj.csv')\n",
    "df = pd.merge(adj, stars, how='left', on='business_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_neg=nltk.FreqDist(df['neg_words'][i][2:(len(df['neg_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_neg.keys()))>=5:\n",
    "        neg_top5.append(list(dict_neg.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        neg_top5.append(list(dict_neg.keys()))\n",
    "    else:\n",
    "        neg_top5.append('NULL')\n",
    "df['neg_top5']=neg_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_pos=nltk.FreqDist(df['pos_words'][i][2:(len(df['pos_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_pos.keys()))>=5:\n",
    "        pos_top5.append(list(dict_pos.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        pos_top5.append(list(dict_pos.keys()))\n",
    "    else:\n",
    "        pos_top5.append('NULL')\n",
    "df['pos_top5']=pos_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['business_id','neg_words','neg_count','neg_top5','pos_words','pos_count','pos_top5','all_mention','review_count','word_count','stars']]\n",
    "df.to_csv('craft_adj.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# beer selection adj for each business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(id_list)\n",
    "select_adj_list=[]\n",
    "for i in range(len(id_list)):\n",
    "    temp=[]\n",
    "    count_pos=0\n",
    "    count_neg=0\n",
    "    list_pos=[]\n",
    "    list_neg=[]\n",
    "    dict={}\n",
    "    dict['business_id']=id_list[i]\n",
    "    for j in range(len(reviewsTEXT_clean)):\n",
    "        if reviewsTEXT_clean[j]['business_id'] == id_list[i]:\n",
    "            temp.append(reviewsTEXT_clean[j])\n",
    "    \n",
    "    word_count=0\n",
    "    for m in range(len(temp)):\n",
    "        word_count+=len(temp[m]['text_split'])\n",
    "        if 'beer select' in temp[m]['text']:\n",
    "            index_list=[p for p,x in enumerate(temp[m]['text_split']) if x=='select']\n",
    "            for index in index_list:\n",
    "                if (index-3 >= 0) and (temp[m]['text_split'][index-3] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-3])\n",
    "                elif (index-3 >= 0) and (temp[m]['text_split'][index-3] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-3])\n",
    "            \n",
    "                if (index-2 >= 0) and (temp[m]['text_split'][index-2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-2])\n",
    "                elif (index-2 >= 0) and (temp[m]['text_split'][index-2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-2])\n",
    "            \n",
    "                if (index+2 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+1])\n",
    "                elif (index+2 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+1])\n",
    "            \n",
    "                if (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+2])\n",
    "                elif (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+2])\n",
    "            \n",
    "    dict['pos_words']=list_pos\n",
    "    dict['neg_words']=list_neg\n",
    "    dict['pos_count']=count_pos\n",
    "    dict['neg_count']=count_neg\n",
    "    dict['all_mention']=count_pos+count_neg\n",
    "    dict['review_count']=len(temp)\n",
    "    dict['word_count']=word_count\n",
    "    select_adj_list.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_adj_df=pd.DataFrame.from_dict(select_adj_list)\n",
    "select_adj_df=select_adj_df[['business_id','neg_words','neg_count','pos_words','pos_count','all_mention','review_count','word_count']]\n",
    "select_adj_df=select_adj_df.sort_values(by=\"all_mention\", ascending=False)\n",
    "select_adj_df.to_csv('select_adj.csv',index=False)\n",
    "\n",
    "adj = pd.read_csv('select_adj.csv')\n",
    "df = pd.merge(adj, stars, how='left', on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_neg=nltk.FreqDist(df['neg_words'][i][2:(len(df['neg_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_neg.keys()))>=5:\n",
    "        neg_top5.append(list(dict_neg.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        neg_top5.append(list(dict_neg.keys()))\n",
    "    else:\n",
    "        neg_top5.append('NULL')\n",
    "df['neg_top5']=neg_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_pos=nltk.FreqDist(df['pos_words'][i][2:(len(df['pos_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_pos.keys()))>=5:\n",
    "        pos_top5.append(list(dict_pos.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        pos_top5.append(list(dict_pos.keys()))\n",
    "    else:\n",
    "        pos_top5.append('NULL')\n",
    "df['pos_top5']=pos_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['business_id','neg_words','neg_count','neg_top5','pos_words','pos_count','pos_top5','all_mention','review_count','word_count','stars']]\n",
    "df.to_csv('select_adj.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draft beer adj for each business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_adj_list=[]\n",
    "for i in range(len(id_list)):\n",
    "    temp=[]\n",
    "    count_pos=0\n",
    "    count_neg=0\n",
    "    list_pos=[]\n",
    "    list_neg=[]\n",
    "    dict={}\n",
    "    dict['business_id']=id_list[i]\n",
    "    for j in range(len(reviewsTEXT_clean)):\n",
    "        if reviewsTEXT_clean[j]['business_id'] == id_list[i]:\n",
    "            temp.append(reviewsTEXT_clean[j])\n",
    "    \n",
    "    word_count=0\n",
    "    for m in range(len(temp)):\n",
    "        word_count+=len(temp[m]['text_split'])\n",
    "        if 'draft beer' in temp[m]['text']:\n",
    "            index_list=[p for p,x in enumerate(temp[m]['text_split']) if x=='draft']\n",
    "            for index in index_list:\n",
    "                if (index-2 >= 0) and (temp[m]['text_split'][index-2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-2])\n",
    "                elif (index-2 >= 0) and (temp[m]['text_split'][index-2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-2])\n",
    "            \n",
    "                if (index-1 >= 0) and (temp[m]['text_split'][index-1] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index-1])\n",
    "                elif (index-1 >= 0) and (temp[m]['text_split'][index-1] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index-1])\n",
    "            \n",
    "                if (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+2])\n",
    "                elif (index+3 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+2] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+2])\n",
    "            \n",
    "                if (index+4 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+3] in pos):\n",
    "                    count_pos+=1\n",
    "                    list_pos.append(temp[m]['text_split'][index+3])\n",
    "                elif (index+4 <= len(temp[m]['text_split'])) and (temp[m]['text_split'][index+3] in neg):\n",
    "                    count_neg+=1\n",
    "                    list_neg.append(temp[m]['text_split'][index+3])\n",
    "            \n",
    "    dict['pos_words']=list_pos\n",
    "    dict['neg_words']=list_neg\n",
    "    dict['pos_count']=count_pos\n",
    "    dict['neg_count']=count_neg\n",
    "    dict['all_mention']=count_pos+count_neg\n",
    "    dict['review_count']=len(temp)\n",
    "    dict['word_count']=word_count\n",
    "    draft_adj_list.append(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "draft_adj_df=pd.DataFrame.from_dict(draft_adj_list)\n",
    "draft_adj_df=draft_adj_df[['business_id','neg_words','neg_count','pos_words','pos_count','all_mention','review_count','word_count']]\n",
    "draft_adj_df=draft_adj_df.sort_values(by=\"all_mention\", ascending=False)\n",
    "draft_adj_df.to_csv('draft_adj.csv',index=False)\n",
    "\n",
    "adj = pd.read_csv('draft_adj.csv')\n",
    "df = pd.merge(adj, stars, how='left', on='business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_neg=nltk.FreqDist(df['neg_words'][i][2:(len(df['neg_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_neg.keys()))>=5:\n",
    "        neg_top5.append(list(dict_neg.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        neg_top5.append(list(dict_neg.keys()))\n",
    "    else:\n",
    "        neg_top5.append('NULL')\n",
    "df['neg_top5']=neg_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_top5=[]\n",
    "for i in range(len(df)):\n",
    "    dict_pos=nltk.FreqDist(df['pos_words'][i][2:(len(df['pos_words'][i])-2)].split('\\', \\''))\n",
    "    if len(list(dict_pos.keys()))>=5:\n",
    "        pos_top5.append(list(dict_pos.keys())[0:5])\n",
    "    elif len(list(dict_neg.keys()))>0:\n",
    "        pos_top5.append(list(dict_pos.keys()))\n",
    "    else:\n",
    "        pos_top5.append('NULL')\n",
    "df['pos_top5']=pos_top5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['business_id','neg_words','neg_count','neg_top5','pos_words','pos_count','pos_top5','all_mention','review_count','word_count','stars']]\n",
    "df.to_csv('draft_adj.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
