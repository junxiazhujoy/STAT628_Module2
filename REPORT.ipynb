{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nightlife in Las Vegas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Junxia Zhu, Yiqun Jiang, Yingjing Jiang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we analysed yelp data focusing on nightlife and bars in Las Vegas. We aimed to explore which factors influenced ratings of reviews and furthermore, give advice to owners for improving the ratings. Our work could be mainly divided into two parts: keys word analysis from reviews and feature extraction from attributes. For the first part, We use Python to do nature language provessing finding meaningful key words. For the latter, we applied random forest algorithm and used ANOVA. We interpreted the factors and made suggesstions due to outcomes. Besides, we also construct prediction models to achieve a \"bonus\" goal for predicting ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Yelp data includes 4 json files: review_train.json, review_test.json, business_train.json, business_test.json, which contains 5364626 reviews, 1321274 reviews, 154606 businesses and 38000 businesses respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Goal1--Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Data Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the analysis part, we focused on the two train data files which has 5364626 reviews for 154606 business. After filtered by \"bars\", \"nightlife\" and \"Las Vagas\" to fit our thesis, the total data involved in this part includes about 265847 reviews for 1201 bars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Business Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. There are nested dictionaries in business attributes, so we first extracted all dictionaries as a new attribute list.   \n",
    "2. Then we calcualted average star of all reviews for each business and set the average stars as our response variables to see the relationships between ratings and attributes.   \n",
    "3. One point need to be metioned is that many attributes have missing values so we mark the blank with \"unknown\", which is treated as a new level.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Important Attributes Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used random forest computing variable importance scores to select useful attributes. \"NoiseLevel\" and \"RestaurantPriceRange\" are of the top importance, which means these two attributes are highly related to ratings. We did one-way ANOVA for both attributes, the model and outcomes are as below:\n",
    "\n",
    "| Model | P-value | result |\n",
    "|:---------:| :-------------------------: |:----------:|\n",
    "| stars~NoiseLevel |  4.36*10e-8  | reject H_0 |\n",
    "| stars~RestaurantPriceRange |  2.44*10e-3  | reject H_0 |\n",
    " \n",
    "According to the results, we reject H_0--there is no differences between different levels of attributes, which means there does exist discrepancy between different levels of NoiseLevel and RestaurantPriceRange.\n",
    "\n",
    "We also want to check interaction between these two attributes, so we construct full model with interaction term. The outcome is shown in below:\n",
    "\n",
    "\n",
    "|  terms | P-value |\n",
    "|:---------:| :-------------------------: |\n",
    "|NoiseLevel |  3.02*e-8 | \n",
    "|RestaurantPriceRange  |  3.50*e-3  |\n",
    "|NoiseLevel*RestaurantPriceRange |  3.58*e-2  |\n",
    "\n",
    "From the table above, we know that all terms in the full model are significant, so except for NoiseLevel and RestaurantPriceRange, their interaction also relates to ratings. Besides, we compare full model with all reduced models and found it had the lowest RSS, which means it is the best model. This result also testify that the outcome of two-way ANOVA is reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Missing Value Analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the random forest results, we can not identify the influence of missing values, so we applied decision tree method using GUIDE-a software for machine learning. \n",
    "\n",
    "    \n",
    "# TODO: Insert the tree plot\n",
    "The plot gave us insights about how missing value related to ratings. TODO: detailed explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Review Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenize each reviews, which means break paragraphs to sentences.\n",
    "2. To deal with negative tone in reviews, we check each sentences and add \"NOT_\" to each word in those sentences.\n",
    "3. As what we cared about is text, so we removed punctuations and meaningless symbols. \n",
    "4. For each word, we do stemming which could avoid different word forms caused by tense, singular and plural. Then we were able to break each reviews to words and counted frequency.\n",
    "5. In the word lists, some words like \"is\", \"the\" actually make no sense so we constructed a stopword list to remove all these useless word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Key Word Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first divided words into four aspects: food, beverage, entertainment and service, and then chose high-rate words from these four aspects respectively. Here, to deviod baseline differences' influence of star distributions, we divided word frequency by the number of words in reviews of each star level, which changed the frequency to rates. To be more specific for our word analysis, we picked words exclusive to bars like \"beer\", \"cocktail\", \"strip\", \"casino\", and plotted histograms of each stars to see if there existed special patterns. \n",
    "\n",
    "And when we tried to interpret the histograms, we found the pattern for the word \"beer\" is really hard to explain since the rates of each star level are nearly the same. So upon previous unigram analysis, we developed bigrams to reach deeper exploration for beers. We found \"beer selection\", \"draft beer\" and \"craft beer\" are of top rates.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src=\"craft_beer.png\" width=400 height=500> </td>\n",
    "<td><img src=\"draft_beer.png\" width=400 height=500> </td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, we search the adjectives next to the bigrams to get more information. And with analysis for the adjectives, we are able to give corresponding advice. To make our conclusions easily understandable, we made a shiny app to visualize our results. Here is the link for the shiny app: https://yingjingjiang.shinyapps.io/shiny_app/    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import rcParams\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 11 ,8\n",
    "img_A = mpimg.imread('\\path\\to\\img_A.png')\n",
    "img_B = mpimg.imread('\\path\\to\\img_B.png')\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(img_A);\n",
    "ax[1].imshow(img_B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Goal2--Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we combined features extracted from both reviews and attributes. We made dataframe with columns of key words and attibutes and then constructed several models to predict. For reviews, we applied TFIDF \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusions and Our Advice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Strength and Weakness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strength:\n",
    "1. Carefully deal with the reviews and take care of different baselines.\n",
    "2. Use several methods to confirm our results, which makes our conclusion robust.\n",
    "3. Consider NA as a level to see whether it makes differences but not simply omit them.\n",
    "\n",
    "### Weakness:\n",
    "1. Fail to find patterns in time and hour analysis, which may need more careful inspectation.\n",
    "2. Hard to interpret tree method outcome objectively more out of subjective analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contribution: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Goal1:   \n",
    "* Business Analysis:   \n",
    "    Data cleaning: Junxia Zhu, Yiqun Jiang, Yingjing Jiang  \n",
    "    Model: Yiqun Jiang, Yingjing Jiang  \n",
    "    Plots: Junxia Zhu  \n",
    "* Word Analysis:   \n",
    "    Data cleaning: Yiqun Jiang, Junxia Zhu  \n",
    "    Ngrams generating: Yiqun Jiang  \n",
    "    Adj analysis: Junxia Zhu  \n",
    "    Plots: Junxia Zhu  \n",
    "    Shiny app: Yingjing Jiang  \n",
    "    \n",
    "#### 2. Goal2:  \n",
    "* Kaggle: Junxia Zhu, Yiqun Jiang, Yingjing Jiang  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "[1] GUIDE Manual: http://www.stat.wisc.edu/~loh/treeprogs/guide/guideman.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
